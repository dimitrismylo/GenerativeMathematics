{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yq9vFcJy5Yc"
      },
      "source": [
        "<h1><b>Text Generation for</b>\n",
        "<b>Mathematical Problems</b></h1>\n",
        "\n",
        "\n",
        "In the following notebook, methods of generating textual mathematical problems are explored.\n",
        "\n",
        "This will be achieved by applying several different Deep Learning generative text models to the [DeepMind Mathematics Dataset](https://github.com/deepmind/mathematics_dataset).\n",
        "\n",
        "\n",
        "This dataset contains questions-answer pairs for a multitude of different topics eg. calculus, probability, algebra. Files are seperated by topic. Example questions are shown below.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Question: Solve -42*r + 27*c = -1167 and 130*r + 4*c = 372 for r.\n",
        "Answer: 4\n",
        "\n",
        "Question: Calculate -841880142.544 + 411127.\n",
        "Answer: -841469015.544\n",
        "\n",
        "Question: Let x(g) = 9*g + 1. Let q(c) = 2*c + 1. Let f(i) = 3*i - 39. Let w(j) = q(x(j)). Calculate f(w(a)).\n",
        "Answer: 54*a - 30\n",
        "\n",
        "Question: Let e(l) = l - 6. Is 2 a factor of both e(9) and 2?\n",
        "Answer: False\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Model 1: Simple RNN for calculus questions**\n",
        "\n",
        "First, using a simple RNN model, we will try to generate some text on a character level, by training on a single file of our choice."
      ],
      "metadata": {
        "id": "viCxBV2S0xBr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qimlegAk62xO"
      },
      "source": [
        "## Importing modules and the data\n",
        "Performing required imports, mounting Google Drive and checking for GPU. For training, sample dataset must be downloaded from the mathematics dataset Github and put into Google Drive.\n",
        "\n",
        "Make sure that the GPU is enabled in the Google Colab settings (`Edit -> Notebook Settings -> Hardware accelerator -> GPU`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Wv9ubWzhLk",
        "outputId": "8c748427-fbf6-4610-d42f-534b0fa8bde0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "2.8.0\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R4FC9zo38hrK"
      },
      "outputs": [],
      "source": [
        "# Load data from mathematics dataset. Text files are formatted in\n",
        "# pairs of Question-Answer and so the line with the answer is ommitted\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"calculus__differentiate_composed.txt\"  # @param {type: \"string\"}\n",
        "\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "#text = open(training_file_path, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "\n",
        "text = (''.join(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKueoITf-P06",
        "outputId": "6f6f1aca-7475-40ec-d9a2-0539d99d896a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80394849\n",
            "<class 'str'>\n",
            "What is the derivative of -92 + 7238*g**2 - 3619*g**2 + 3*g + 15*g**4 - 3621*g**2 - 3*g wrt g?\n",
            "Let d(o) = 6015*o - 9339. Let b(j) = 859*j - 1334. Let c(n) = -27*b(n) + 4*d(n). Find the first derivative of c(q) wrt q.\n",
            "Let r(y) be the second derivative of 787*y**4/4 - 168*y**2 - 1718*y. What is the de\n"
          ]
        }
      ],
      "source": [
        "# Testing our text length\n",
        "print(len(text))\n",
        "print(type(text))\n",
        "print(text[0:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorising the text and creating the inputs and targets\n",
        "\n",
        "Next, we must create dictionaries mapping each unique character to an index an another dictionary to be able to invert this operation. These are used to create input and target dataset for our model."
      ],
      "metadata": {
        "id": "HQYN9u663VIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    vocabulary = sorted(set(text))  # The list of unique characters in the file\n",
        "    # Creating a mapping each unique character to an index and vice versa\n",
        "    char2idx = {value:key for key, value in enumerate(vocabulary)}\n",
        "    idx2char = {value:key for key, value in char2idx.items()}\n",
        "    text_as_int = np.array([char2idx[c] for c in text]) # Text translated to indices\n",
        "    return text_as_int, vocabulary, char2idx, idx2char\n",
        "\n",
        "def split_batches(batch):\n",
        "    # Target text is the input text sliding along one character eg. Input: \"operatio\" Target: \"peration\"\n",
        "    input_text, target_text = batch[:-1], batch[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "# Create the batched dataset\n",
        "def define_dataset(text_as_int, max_length, batch_size, buffer_size):\n",
        "    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "    dataset = char_dataset.batch(max_length + 1, drop_remainder=True).map(split_batches)\n",
        "    dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "2vcHVPl0gNU5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2KPOs09qAvrL"
      },
      "outputs": [],
      "source": [
        "text_as_int, vocabulary, char2idx, idx2char = process_text(text)\n",
        "\n",
        "dataset = define_dataset(text_as_int, max_length=100, batch_size=512, buffer_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary)\n",
        "print(text_as_int)\n",
        "print(char2idx)\n",
        "\n",
        "print((dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr6Z-A_hnFKp",
        "outputId": "393b2a42-51fb-4387-a409-9d016c6e88b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '?', 'D', 'F', 'L', 'S', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "[26 34 27 ... 45  8  0]\n",
            "{'\\n': 0, ' ': 1, '(': 2, ')': 3, '*': 4, '+': 5, ',': 6, '-': 7, '.': 8, '/': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, '=': 20, '?': 21, 'D': 22, 'F': 23, 'L': 24, 'S': 25, 'W': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52}\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(512, 100), dtype=tf.int64, name=None), TensorSpec(shape=(512, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining and training our model\n",
        "\n",
        "Next, we can define our RNN model that will be used to generate text and that we will train with the dataset we have created."
      ],
      "metadata": {
        "id": "FjpOpxkDspkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "def build_model(vocab_size=len(vocabulary), embedding_dim=256, rnn_units=1024, batch_size=512):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Rnvq4SWdtDaC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer, loss=loss)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq9DqSB1xsMx",
        "outputId": "dc58e277-4acd-436d-c5c9-f7cb414be89b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (512, None, 256)          13568     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (512, None, 1024)         1311744   \n",
            "                                                                 \n",
            " dense (Dense)               (512, None, 53)           54325     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,379,637\n",
            "Trainable params: 1,379,637\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=2)\n",
        "model.save_weights(\"gen_text_weights.h5\", save_format='h5')\n",
        "# To keep this prediction step simple, use a batch size of 1\n",
        "gen_model = build_model(vocab_size=len(vocabulary), batch_size=1)\n",
        "gen_model.load_weights(\"gen_text_weights.h5\")\n",
        "gen_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DD72cabyEV2",
        "outputId": "6eb6cb30-ca7b-41de-f8e0-74d2450bcb53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1554/1554 [==============================] - 281s 179ms/step - loss: 0.9297\n",
            "Epoch 2/2\n",
            "1554/1554 [==============================] - 269s 173ms/step - loss: 0.7537\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            13568     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (1, None, 1024)           1311744   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 53)             54325     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,379,637\n",
            "Trainable params: 1,379,637\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating text\n",
        "\n",
        "Now that we have trained our model we can define a new model of batch size 1 with the same weights, to generate text data given a prompt."
      ],
      "metadata": {
        "id": "4ud6edY8zBFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F1h69gsLA_-K"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string, generate_char_num=1000, char2idx=char2idx, idx2char=idx2char):\n",
        "    # First, vectorise the input to the function\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "\n",
        "    text_generated = []  # Empty string to store our results\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(generate_char_num):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)  # remove the batch dimension\n",
        "\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # We pass the predicted character as the next input to the model along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], axis=0)\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation of our text!\n",
        "\n",
        "input_text = \"L\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000#@param \n",
        "generated_text = generate_text(gen_model, start_string=input_text, generate_char_num=n_characters_output)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjna7KgQ_yL0",
        "outputId": "a7260aae-2e00-4c10-a9e4-8753dd3c2b27"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let y be l(-1). Let m(o) wrt o.\n",
            "Suppose -18*w + 44 - 404 = -3*x + 3*p, x = b - 196. Let k be 8 + (t + (-52)/6). Let w be (-12 + 5)*(110/(-686)) - 2918/9. What is the first derivative of 2*a**4 - 8*a - 1906*a**f + 0*a**5 wrt a.\n",
            "Find the second derivative of 633*i**3 + 117947*i + 6152*i**6 wrt i.\n",
            "Differentiate -1827 + 1388*r**2 - 548 - 186369 - 31216*r - 1524*r + 41801 wrt r.\n",
            "Let w(w) be the third derivative of -53*w**6/40 + 197*w**3/6 - 4*w**2 - 68*w. What is the second derivative of n(m) wrt m?\n",
            "Differentiate -2240727*j**3 - 1856978589 - 187099 + 8897 + 791787*j - 95 wrt j.\n",
            "Let a(l) be the first derivative of -969*l**4/4 + 2455*l + 1470. Differentiate x(b) with respect to b.\n",
            "What is the third derivative of 17*f t.\n",
            "Suppose y - 137 = 14*d - 2*h, 3*w = 0 + 5. Find the second derivative of -2 tive of p(o) wrt o.\n",
            "Let q(b) be the third derivative of 871697*b**8/53 + b**5/20 + b**4/12 - 4*b**3 + 5*b**2 + 3*b - 14. What is the first derivative of h(k) wrt k?\n",
            "Let z(d) be the third derivative of -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_list = generated_text.split(\"\\n\")\n",
        "\n",
        "print(question_list[0])\n",
        "print(question_list[1])\n",
        "print(question_list[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQPMQ0BLf2wV",
        "outputId": "0bf40185-dcee-424a-e8d8-d297c2071c26"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let y be l(-1). Let m(o) wrt o.\n",
            "Suppose -18*w + 44 - 404 = -3*x + 3*p, x = b - 196. Let k be 8 + (t + (-52)/6). Let w be (-12 + 5)*(110/(-686)) - 2918/9. What is the first derivative of 2*a**4 - 8*a - 1906*a**f + 0*a**5 wrt a.\n",
            "Find the second derivative of 633*i**3 + 117947*i + 6152*i**6 wrt i.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The questions generated display encouraging results. Some questions produced make sense sequentially (expression given and then task to be completed stated) and the mathematical equations are almost always differentiable. This gives the appearance that the questions make sense at first glance but with a closer look most of the questions are not solvable. \n",
        "\n",
        "The main problem that occurs is the one seen in the following question\n",
        "\n",
        "\n",
        "```\n",
        "Let a(l) be the first derivative of -969*l**4/4 + 2455*l + 1470. Differentiate x(b) with respect to b.\n",
        "```\n",
        "\n",
        "Both parts of the question make sense on their own. The first states an equation a(l) and the second part asks you to differentiate x(b) with respect to b. However, when putting the two together, the question becomes unsolvable. \n",
        "\n",
        "Despite this, some questions like the following are not only solvable but do not appear in the original dataset and so are completely new questions!\n",
        "\n",
        "\n",
        "```\n",
        "Find the second derivative of 633*i**3 + 117947*i + 6152*i**6 wrt i.\n",
        "\n",
        "Differentiate -1827 + 1388*r**2 - 548 - 186369 - 31216*r - 1524*r + 41801 wrt r.\n",
        "```"
      ],
      "metadata": {
        "id": "9dwFtOOzuXLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Investigation of RNN model for different topics**\n",
        "\n",
        "In the previous section we saw that the model struggles with longer questions, seemingly forgetting what the equation concering us consisted of, resulting in questions that do not make sense as a whole. \n",
        "\n",
        "In this section, the model will be tested with questions in different topics to gain insight into what it does well and where it fails."
      ],
      "metadata": {
        "id": "4djFzC-huOmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions on conversion of units\n"
      ],
      "metadata": {
        "id": "DegUhryITgt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"measurement__conversion.txt\"  # @param {type: \"string\"}\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "text1 = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text1 = (''.join(text1))\n",
        "\n",
        "# Create vectorised dataset\n",
        "text_as_int1, vocabulary1, char2idx1, idx2char1 = process_text(text1)\n",
        "dataset1 = define_dataset(text_as_int1, max_length=100, batch_size=512, buffer_size=10000)\n",
        "\n",
        "#Compile model\n",
        "model1 = build_model(vocab_size=len(vocabulary1))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model1.compile(optimizer, loss=loss)\n",
        "\n",
        "\n",
        "#Train model\n",
        "history1 = model1.fit(dataset1, epochs=2)\n",
        "model1.save_weights(\"gen_text_weights1.h5\", save_format='h5')\n",
        "gen_model1 = build_model(vocab_size=len(vocabulary1), batch_size=1)\n",
        "gen_model1.load_weights(\"gen_text_weights1.h5\")\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "input_text = \"W\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000#@param \n",
        "generated_text1 = generate_text(gen_model1, start_string=input_text, generate_char_num=n_characters_output, char2idx=char2idx1, idx2char=idx2char1)\n",
        "print(generated_text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODGJEFsuTtin",
        "outputId": "612b0add-6f05-4027-a6a4-80899d6df119"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "580/580 [==============================] - 109s 168ms/step - loss: 0.7808\n",
            "Epoch 2/2\n",
            "580/580 [==============================] - 99s 168ms/step - loss: 0.4783\n",
            "What is 45665.83 litres in illilitres?\n",
            "What is 0.0378906 centuries to decades.\n",
            "Convert 51.79456 centimeters to meters.\n",
            "Convert 671.4646 centuries to months.\n",
            "What is 13/3 of a kilogram in grams?\n",
            "How many nanoseconds are there in 8250.019ns?\n",
            "What is 559.8863 nanoseconds in hours?\n",
            "What is 1/4 of a millimeter?\n",
            "How many millilitres are there in seventy-nine fifths of a litre?\n",
            "What is 0.698131 tonnes in milligrams?\n",
            "How many decades are there in twenty-nine f anvert 4362.372 millennia to decades.\n",
            "What is 14.6365t in micrograms?\n",
            "What is four thirds of a litre in millilitres?\n",
            "What is 5/4 of a milligram in micrograms?\n",
            "How many seconds are there in 45/4 of a week?\n",
            "How many months are there in 0.5404472 millennia?\n",
            "How many millilitres are there in 25/4 of a litre?\n",
            "Convert 17241.157 weeks to daysHow many millilitres are there in 11/5 of a litre?\n",
            "How many years are there in 7188 meters?\n",
            "How many kilograms to micrograms.\n",
            "What is thirty-two fifths of a litre in millilitres?\n",
            "What is 55.53629ml in litres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the questions produced are of quite good value. They almost always have units that coincide with each other (nanoseconds-hours, centimeters-meters etc) and make sense gramatically. The questions are generally small and so we may not be encountering the problem of \"forgetting\" the earlier part of the question."
      ],
      "metadata": {
        "id": "ySNmP0iCaaNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions on Greatest Common Divisor"
      ],
      "metadata": {
        "id": "0zXzOzSElglA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"numbers__gcd_composed.txt\"  # @param {type: \"string\"}\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "text2 = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text2 = (''.join(text2))\n",
        "\n",
        "# Create vectorised dataset\n",
        "text_as_int2, vocabulary2, char2idx2, idx2char2 = process_text(text2)\n",
        "dataset2 = define_dataset(text_as_int2, max_length=100, batch_size=512, buffer_size=10000)\n",
        "\n",
        "#Compile model\n",
        "model2 = build_model(vocab_size=len(vocabulary2))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model2.compile(optimizer, loss=loss)\n",
        " \n",
        "\n",
        "#Train model\n",
        "history2 = model2.fit(dataset2, epochs=2)\n",
        "model2.save_weights(\"gen_text_weights2.h5\", save_format='h5')\n",
        "gen_model2 = build_model(vocab_size=len(vocabulary2), batch_size=1)\n",
        "gen_model2.load_weights(\"gen_text_weights2.h5\")\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "input_text = \"W\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000#@param \n",
        "generated_text2 = generate_text(gen_model2, start_string=input_text, generate_char_num=n_characters_output, char2idx=char2idx2, idx2char=idx2char2)\n",
        "print(generated_text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8UgOfUNljq7",
        "outputId": "35bbbd64-3932-4ba8-dec5-ecc4a1c8b74a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1446/1446 [==============================] - 244s 167ms/step - loss: 0.9501\n",
            "Epoch 2/2\n",
            "1446/1446 [==============================] - 243s 168ms/step - loss: 0.7552\n",
            "What is the highest common divisor of d and 273?\n",
            "Suppose 5*u - 2021 = 2*m, 2*u - 2*f = -2*u = -175 + 226. What is the greatest common divisor of m and 49?\n",
            "Let u be -5 + -2 - -1 + -1. Let j be 17/((-75)/(-9)). What is the highest common factor of 26160 and c?\n",
            "Let m be 1 - 0 - (142/(-54)*-90)/((-2)/(-165))). Calculate the highest common factor of h and 20.\n",
            "Let u(q) = -26 s = 3*u. What is the highest common factor of s and x?\n",
            "Suppose -5*o + 4*t = 4*f - 255, -3*x - 951 = -5*a. Calculate the greatest common factor of q and 2298.\n",
            "Let w be 6 1*v + 96, 4*l - 12*o + 923 = 25*f. Suppose 35*s = 3*s - 140. What is the greatest common divisor of 273 and i?\n",
            "Suppose 9*l - 4230 = 10156. Calculate the greatest common divisor of a and f.\n",
            "Suppose h - 32 = 9. Suppose -5*b + 4*o + j = 0. Calculate the greatest common factor of 1000 and g.\n",
            "Suppose 2*t - 24 = -p, 5*l + 2*m + 67 = 3*f. What is the greatest common factor of m and q?\n",
            "Let o(a) = 6*a - 1. Let s be v(-5). What is the highest common divisor of t and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These questions are in general more complicated and the model fails to produce quality questions, obviously mixing variables together. "
      ],
      "metadata": {
        "id": "UEp8gIopbL2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions on Linear Algebra\n",
        "\n",
        "Here 2 versions of questions on linear algebra are produced. As we can see the simpler version of the questions produce great original solvable questions but that cannot be said for the more complicated questions with more information."
      ],
      "metadata": {
        "id": "pOEpOIkIM3hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"algebra__linear_1d_composed.txt\"  # @param {type: \"string\"}\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "text3 = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text3 = (''.join(text3))\n",
        "\n",
        "# Create vectorised dataset\n",
        "text_as_int3, vocabulary3, char2idx3, idx2char3 = process_text(text3)\n",
        "dataset3 = define_dataset(text_as_int3, max_length=100, batch_size=512, buffer_size=10000)\n",
        "\n",
        "#Compile model\n",
        "model3 = build_model(vocab_size=len(vocabulary3))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model3.compile(optimizer, loss=loss)\n",
        " \n",
        "\n",
        "#Train model\n",
        "history3 = model3.fit(dataset3, epochs=2)\n",
        "model3.save_weights(\"gen_text_weights3.h5\", save_format='h5')\n",
        "gen_model3 = build_model(vocab_size=len(vocabulary3), batch_size=1)\n",
        "gen_model3.load_weights(\"gen_text_weights3.h5\")\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "input_text = \"S\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000#@param \n",
        "generated_text3 = generate_text(gen_model3, start_string=input_text, generate_char_num=n_characters_output, char2idx=char2idx3, idx2char=idx2char3)\n",
        "print(generated_text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T341WQZqNUlh",
        "outputId": "e0568c3f-db46-476d-b494-d0c4f27e5f4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1212/1212 [==============================] - 260s 213ms/step - loss: 1.1832\n",
            "Epoch 2/2\n",
            "1212/1212 [==============================] - 262s 215ms/step - loss: 0.9736\n",
            "Suppose 5*h - 130 = 7*h. Let p(g) = -2*g - 8. Let u be r(g). Suppose -4*n = 8*t - 16. Suppose 5*x = a + 27. Let m = -2 + h. Solve m*s + 41*s = r for s.\n",
            "Suppose 4*h - 3 + 36 = 06. Let h(d) = d**2 - 12*d - 23. Let d be w(1). Suppose 13*k - l = 10*k - 76. Solve -4*a = -s - y for a.\n",
            "Suppose -5*d - 123 = 4*q + 29, -2*i = i - 13. Suppose 3*a = 15 - 7. Solve d*d - s = 2 for d.\n",
            "Let u = 49 - -12. Let v = 30 - h. Solve v + 1 = -l for v.\n",
            "Let j be (12 - 253) + 2 + -3. Solve c*d + 6 = 29*d for d.\n",
            "Let y(m) = -1822 - 14501. Let i be p(12). Solve u*q = 145*q - 40 for q.\n",
            "Let x be ((-8)/5)/(-1*(-48)/(-44). Suppose 0 = c*v + 45 - 48. Solve -v = -l - 5*c for c.\n",
            "Suppose 4*p = -t 10. Suppose 11*b = -v - 92. Solve -25*w = -w*w + 606 for w.\n",
            "Let o be ((-6)/(-16))/(4/10). Let y be 2 + z = -46 + j. Let k be (-22)/17 - 6/x. Solve + 11 = 5*f. Solve -g*x = 3 - 5 for x.\n",
            "Let n be (-12)/(-6) - (-29 + 35). Suppose a + 4*g + w = 13, -4*a + 37 = -3*k + 16. Suppose -5*m = -f*t - 49, -154 = -3*t + u - 545. Suppose -l + 11 =\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"algebra__linear_1d.txt\"  # @param {type: \"string\"}\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "text4 = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text4 = (''.join(text4))\n",
        "\n",
        "# Create vectorised dataset\n",
        "text_as_int4, vocabulary4, char2idx4, idx2char4 = process_text(text4)\n",
        "dataset4 = define_dataset(text_as_int4, max_length=100, batch_size=512, buffer_size=10000)\n",
        "\n",
        "#Compile model\n",
        "model4 = build_model(vocab_size=len(vocabulary4))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model4.compile(optimizer, loss=loss)\n",
        " \n",
        "\n",
        "#Train model\n",
        "history4 = model4.fit(dataset4, epochs=2)\n",
        "model4.save_weights(\"gen_text_weights4.h5\", save_format='h5')\n",
        "gen_model4 = build_model(vocab_size=len(vocabulary4), batch_size=1)\n",
        "gen_model4.load_weights(\"gen_text_weights4.h5\")\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "input_text = \"S\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000#@param \n",
        "generated_text4 = generate_text(gen_model4, start_string=input_text, generate_char_num=n_characters_output, char2idx=char2idx4, idx2char=idx2char4)\n",
        "print(generated_text4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lwxiwOOaDYU",
        "outputId": "39d0eb1b-9e6b-4aaa-c7cf-b0793ab90dd4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "558/558 [==============================] - 121s 213ms/step - loss: 1.4334\n",
            "Epoch 2/2\n",
            "558/558 [==============================] - 127s 226ms/step - loss: 1.1974\n",
            "Solve -4391 = 395*v - 34 for v.\n",
            "Solve 170*w + 40*w + 28*w + 50*w - 115415 = 0 for w.\n",
            "Solve 17191 = 1842*v - 424*v + 383*v - 1505 for v.\n",
            "Solve -12861*z + 90800 = -3254*z - 3647 for z.\n",
            "Solve -101 - 1597 - 128 + 158 = 0 for w.\n",
            "Solve -7492*j = 2348*j - 1611*j + 720 for j.\n",
            "Solve 371*j + 415*j + 23289 = 12787 - 5538 for j.\n",
            "Solve 21621*w - 2238 = -83689*w for w.\n",
            "Solve -200*o + 892*o + 1459 - 83668 = 0 for b.\n",
            "Solve -1270*a - 23977 = -992*a for a.\n",
            "Solve -55455 = 154*w + 82*w for w.\n",
            "Solve -645*o + 5133 - 1993 = 0 for o.\n",
            "Solve 9536*z - 837003 = 68*f j - 17*j + 5432 = 10*j - 429*j for r.\n",
            "Solve -230 - 313222 = -680*f for f.\n",
            "Solve 0 = -129198 + 185060 for f.\n",
            "Solve 059223 = -160*w - 208163 for w.\n",
            "Solve 3118*z + 128*z = -196*z - 130*z + 21*z - 238*z - 36409 - 4557 = -462*j for j.\n",
            "Solve 75*m - 127716 = -119512 for m.\n",
            "Solve 70*y - 28137 - 89578 - 5371 = -317*n for n.\n",
            "Solve -270*z - 2931 = -174*z + 178*z - 191*z for z.\n",
            "Solve -365*t + 330*t = -1235*t - 3130 - 13268 for t.\n",
            "Solve -40*i + 215*i + 3377 = -39*i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Questions on Probability**"
      ],
      "metadata": {
        "id": "FOdyIZZ_4OSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"probability__swr_p_level_set.txt\"  # @param {type: \"string\"}\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "text3 = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text3 = (''.join(text3))\n",
        "\n",
        "# Create vectorised dataset\n",
        "text_as_int3, vocabulary3, char2idx3, idx2char3 = process_text(text3)\n",
        "dataset3 = define_dataset(text_as_int3, max_length=100, batch_size=512, buffer_size=10000)\n",
        "\n",
        "#Compile model\n",
        "model3 = build_model(vocab_size=len(vocabulary3))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model3.compile(optimizer, loss=loss)\n",
        " \n",
        "\n",
        "#Train model\n",
        "history3 = model3.fit(dataset3, epochs=3)\n",
        "model3.save_weights(\"gen_text_weights3.h5\", save_format='h5')\n",
        "gen_model3 = build_model(vocab_size=len(vocabulary3), batch_size=1)\n",
        "gen_model3.load_weights(\"gen_text_weights3.h5\")\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "input_text = \"W\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000#@param \n",
        "generated_text3 = generate_text(gen_model3, start_string=input_text, generate_char_num=n_characters_output, char2idx=char2idx3, idx2char=idx2char3)\n",
        "print(generated_text3)"
      ],
      "metadata": {
        "id": "bFFvBJHH5SMo",
        "outputId": "8d6e698e-9837-44c3-9ed4-751afa194e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1316/1316 [==============================] - 225s 170ms/step - loss: 0.5827\n",
            "Epoch 2/3\n",
            "1316/1316 [==============================] - 225s 170ms/step - loss: 0.4155\n",
            "Epoch 3/3\n",
            "1316/1316 [==============================] - 224s 170ms/step - loss: 0.4067\n",
            "What is prob of picking 1 z and 1 l?\n",
            "What is prob of picking 1 n, 2 l, and 1 j?\n",
            "Three letters picked without replacement from kqjvkjqqjkvjq. What is prob of picking 1 v, 1 w, and 1 x?\n",
            "Calculate prob of picking 3 d and 1 x when four letters picked without replacement from egcgyf.\n",
            "What is prob of picking 2 x when two letters picked without replacement from {z: 1, c: 1, x: 2}.\n",
            "Three letters picked without replacement from {d: 2, w: 6, f: 4, x: 1}.\n",
            "Three letters picked without replacement from {i: 1, q: 1, z: 2, v: 1, z: 1, g: 1}.\n",
            "Calculate prob of picking 4 g when four letters picked without replacement from {n: 6, v: 1, c: 1, a: 2, d: 3}.\n",
            "Four letters picked without replacement from {w: 3, u: 12}?\n",
            "What is prob of picking 2 z and 2 p when four letters picked without replacement from {a: 1, q: 1, m: 4, k: 2, c: 1, f: 2}. Give prob of picking 1 d, 1 r, 1 k, and 1 b.\n",
            "Two letters picked without replacement from pulbllblllzl. What is prob of picking 4 k?\n",
            "What is prob of picking 3 r when three l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Model 2: LSTM models**\n",
        "\n",
        "To try to mitigate the effect that long questions have on our generated problems a new model is proposed. This model employs the LSTM architecture. In this network, a memory cell is added, that can help our model keep track of long term dependancies and hopefully improve the resulting problems."
      ],
      "metadata": {
        "id": "bpgrqWUrgv-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining our LSTM model"
      ],
      "metadata": {
        "id": "gRmWfE3UjdH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_LSTM_model(vocab_size=len(vocabulary), embedding_dim=256, rnn_units=256, batch_size=512):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2), \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "n6dY9SldjgQq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "training_folder = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file = \"algebra__linear_1d_composed.txt\"  # @param {type: \"string\"}\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "\n",
        "text5 = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text5 = (''.join(text5))\n",
        "\n",
        "# Create vectorised dataset\n",
        "text_as_int5, vocabulary5, char2idx5, idx2char5 = process_text(text5)\n",
        "dataset5 = define_dataset(text_as_int5, max_length=100, batch_size=512, buffer_size=10000)\n",
        "\n",
        "#Compile model\n",
        "model5 = build_LSTM_model(vocab_size=len(vocabulary5))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "model5.compile(optimizer, loss=loss)\n",
        "\n",
        "#Train model\n",
        "history5 = model5.fit(dataset5, epochs=15)\n",
        "model5.save_weights(\"gen_text_weights5.h5\", save_format='h5')\n",
        "gen_model5 = build_LSTM_model(vocab_size=len(vocabulary5), batch_size=1)\n",
        "gen_model5.load_weights(\"gen_text_weights5.h5\")\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "input_text = \"S\"  #@param {type: \"string\"}\n",
        "n_characters_output = 1000 #@param \n",
        "generated_text5 = generate_text(gen_model5, start_string=input_text, generate_char_num=n_characters_output, char2idx=char2idx5, idx2char=idx2char5)\n",
        "print(generated_text5)"
      ],
      "metadata": {
        "id": "WrqKzdu6Br77"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import vis_utils\n",
        "SVG(vis_utils.model_to_dot(model5, show_shapes=True, show_layer_names=True, dpi=60).create(prog='dot', format='svg')) "
      ],
      "metadata": {
        "id": "danhaH8ko8lQ",
        "outputId": "d3d321ee-1130-4942-a610-600f14bde944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"530pt\" viewBox=\"0.00 0.00 392.00 636.00\" width=\"327pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 632)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-632 388,-632 388,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139734886307920 -->\n<g class=\"node\" id=\"node1\">\n<title>139734886307920</title>\n<polygon fill=\"none\" points=\"0,-581.5 0,-627.5 384,-627.5 384,-581.5 0,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-612.3\">embedding_1_input</text>\n<polyline fill=\"none\" points=\"0,-604.5 134,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-589.3\">InputLayer</text>\n<polyline fill=\"none\" points=\"134,-581.5 134,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"134,-604.5 192,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"192,-581.5 192,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-600.8\">[(512, None)]</text>\n<polyline fill=\"none\" points=\"288,-581.5 288,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336\" y=\"-600.8\">[(512, None)]</text>\n</g>\n<!-- 139737420684624 -->\n<g class=\"node\" id=\"node2\">\n<title>139737420684624</title>\n<polygon fill=\"none\" points=\"13,-498.5 13,-544.5 371,-544.5 371,-498.5 13,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"61\" y=\"-529.3\">embedding_1</text>\n<polyline fill=\"none\" points=\"13,-521.5 109,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"61\" y=\"-506.3\">Embedding</text>\n<polyline fill=\"none\" points=\"109,-498.5 109,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"138\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"109,-521.5 167,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"138\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"167,-498.5 167,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-517.8\">(512, None)</text>\n<polyline fill=\"none\" points=\"254,-498.5 254,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-517.8\">(512, None, 256)</text>\n</g>\n<!-- 139734886307920&#45;&gt;139737420684624 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139734886307920-&gt;139737420684624</title>\n<path d=\"M192,-581.3799C192,-573.1745 192,-563.7679 192,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-554.784 192,-544.784 188.5001,-554.784 195.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139732806221136 -->\n<g class=\"node\" id=\"node3\">\n<title>139732806221136</title>\n<polygon fill=\"none\" points=\"13.5,-415.5 13.5,-461.5 370.5,-461.5 370.5,-415.5 13.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-446.3\">dropout</text>\n<polyline fill=\"none\" points=\"13.5,-438.5 78.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-423.3\">Dropout</text>\n<polyline fill=\"none\" points=\"78.5,-415.5 78.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"78.5,-438.5 136.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"136.5,-415.5 136.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-434.8\">(512, None, 256)</text>\n<polyline fill=\"none\" points=\"253.5,-415.5 253.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312\" y=\"-434.8\">(512, None, 256)</text>\n</g>\n<!-- 139737420684624&#45;&gt;139732806221136 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139737420684624-&gt;139732806221136</title>\n<path d=\"M192,-498.3799C192,-490.1745 192,-480.7679 192,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-471.784 192,-461.784 188.5001,-471.784 195.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139734886171856 -->\n<g class=\"node\" id=\"node4\">\n<title>139734886171856</title>\n<polygon fill=\"none\" points=\"18,-332.5 18,-378.5 366,-378.5 366,-332.5 18,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-363.3\">lstm</text>\n<polyline fill=\"none\" points=\"18,-355.5 74,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-340.3\">LSTM</text>\n<polyline fill=\"none\" points=\"74,-332.5 74,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"74,-355.5 132,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"132,-332.5 132,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-351.8\">(512, None, 256)</text>\n<polyline fill=\"none\" points=\"249,-332.5 249,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-351.8\">(512, None, 256)</text>\n</g>\n<!-- 139732806221136&#45;&gt;139734886171856 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139732806221136-&gt;139734886171856</title>\n<path d=\"M192,-415.3799C192,-407.1745 192,-397.7679 192,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-388.784 192,-378.784 188.5001,-388.784 195.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139734888379728 -->\n<g class=\"node\" id=\"node5\">\n<title>139734888379728</title>\n<polygon fill=\"none\" points=\"7.5,-249.5 7.5,-295.5 376.5,-295.5 376.5,-249.5 7.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-280.3\">dropout_1</text>\n<polyline fill=\"none\" points=\"7.5,-272.5 84.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-257.3\">Dropout</text>\n<polyline fill=\"none\" points=\"84.5,-249.5 84.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"84.5,-272.5 142.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"142.5,-249.5 142.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201\" y=\"-268.8\">(512, None, 256)</text>\n<polyline fill=\"none\" points=\"259.5,-249.5 259.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318\" y=\"-268.8\">(512, None, 256)</text>\n</g>\n<!-- 139734886171856&#45;&gt;139734888379728 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139734886171856-&gt;139734888379728</title>\n<path d=\"M192,-332.3799C192,-324.1745 192,-314.7679 192,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-305.784 192,-295.784 188.5001,-305.784 195.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139734886270224 -->\n<g class=\"node\" id=\"node6\">\n<title>139734886270224</title>\n<polygon fill=\"none\" points=\"18,-166.5 18,-212.5 366,-212.5 366,-166.5 18,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-197.3\">lstm_1</text>\n<polyline fill=\"none\" points=\"18,-189.5 74,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-174.3\">LSTM</text>\n<polyline fill=\"none\" points=\"74,-166.5 74,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"74,-189.5 132,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"132,-166.5 132,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-185.8\">(512, None, 256)</text>\n<polyline fill=\"none\" points=\"249,-166.5 249,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-185.8\">(512, None, 256)</text>\n</g>\n<!-- 139734888379728&#45;&gt;139734886270224 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139734888379728-&gt;139734886270224</title>\n<path d=\"M192,-249.3799C192,-241.1745 192,-231.7679 192,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-222.784 192,-212.784 188.5001,-222.784 195.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139734886272912 -->\n<g class=\"node\" id=\"node7\">\n<title>139734886272912</title>\n<polygon fill=\"none\" points=\"7.5,-83.5 7.5,-129.5 376.5,-129.5 376.5,-83.5 7.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-114.3\">dropout_2</text>\n<polyline fill=\"none\" points=\"7.5,-106.5 84.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-91.3\">Dropout</text>\n<polyline fill=\"none\" points=\"84.5,-83.5 84.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"84.5,-106.5 142.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"142.5,-83.5 142.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201\" y=\"-102.8\">(512, None, 256)</text>\n<polyline fill=\"none\" points=\"259.5,-83.5 259.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318\" y=\"-102.8\">(512, None, 256)</text>\n</g>\n<!-- 139734886270224&#45;&gt;139734886272912 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139734886270224-&gt;139734886272912</title>\n<path d=\"M192,-166.3799C192,-158.1745 192,-148.7679 192,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-139.784 192,-129.784 188.5001,-139.784 195.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139734886306512 -->\n<g class=\"node\" id=\"node8\">\n<title>139734886306512</title>\n<polygon fill=\"none\" points=\"17.5,-.5 17.5,-46.5 366.5,-46.5 366.5,-.5 17.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"49.5\" y=\"-31.3\">dense_1</text>\n<polyline fill=\"none\" points=\"17.5,-23.5 81.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"49.5\" y=\"-8.3\">Dense</text>\n<polyline fill=\"none\" points=\"81.5,-.5 81.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"81.5,-23.5 139.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"139.5,-.5 139.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-19.8\">(512, None, 256)</text>\n<polyline fill=\"none\" points=\"256.5,-.5 256.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-19.8\">(512, None, 49)</text>\n</g>\n<!-- 139734886272912&#45;&gt;139734886306512 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139734886272912-&gt;139734886306512</title>\n<path d=\"M192,-83.3799C192,-75.1745 192,-65.7679 192,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"195.5001,-56.784 192,-46.784 188.5001,-56.784 195.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The memory capabilities of the LSTM seem to not have an effect on remembering the variable name during a sentence."
      ],
      "metadata": {
        "id": "59VNiz4XdX39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history5.history\n",
        "\n",
        "#acc = history_dict['acc']\n",
        "#val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "#val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WkOSdeZZzKdM",
        "outputId": "49c064da-55ef-4f35-941e-9e9385afe1e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Multiple Topics with a Singular Generator**\n",
        "\n",
        "Next, the posibility of creating a model that has freedom to generate questions on whatever topic it wants is investigated."
      ],
      "metadata": {
        "id": "c8xgS4pTzHUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging datasets\n",
        "\n",
        "First, multiple different topic files must be merged into one for training the generator."
      ],
      "metadata": {
        "id": "TLpOwTiNdIGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from mathematics dataset. Text files are formatted in\n",
        "# pairs of Question-Answer and so the line with the answer is ommitted\n",
        "\n",
        "# FIRST TOPIC\n",
        "\n",
        "training_folder1 = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file1 = \"measurement__conversion.txt\"  # @param {type: \"string\"}\n",
        "training_file_path1 = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder1+'/'+training_file1\n",
        "text1 = open(training_file_path1, encoding='utf-8').readlines()[::2] \n",
        "text1 = (''.join(text1))\n",
        "\n",
        "# SECOND TOPIC\n",
        "training_folder2 = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file2 = \"algebra__linear_1d.txt\"  # @param {type: \"string\"}\n",
        "training_file_path2 = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder2+'/'+training_file2\n",
        "text2 = open(training_file_path2, encoding='utf-8').readlines()[::2] \n",
        "text2 = (''.join(text2))\n",
        "\n",
        "\n",
        "# Testing our text length\n",
        "print(len(text1))\n",
        "print(len(text2))\n",
        "print(type(text))\n",
        "print(text1[0:500])\n",
        "\n",
        "# Adding both data sets together\n",
        "\n",
        "combined_text = text1 + text2\n",
        "print(len(combined_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbpPnBJ6OoSx",
        "outputId": "5d7f8568-b5ac-4f96-d10f-9704c9bd9c4f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29999472\n",
            "28877367\n",
            "<class 'str'>\n",
            "What is 3/5 of a millimeter in micrometers?\n",
            "What is 2/21 of a week in seconds?\n",
            "What is 88937.07ms in minutes?\n",
            "What is 992214.1 decades in centuries?\n",
            "How many years are there in 3647.718 decades?\n",
            "What is 57/2 of a minute in seconds?\n",
            "Convert 0.2732285ms to microseconds.\n",
            "What is 1/5 of a kilometer in centimeters?\n",
            "What is 51/5 of a milligram in micrograms?\n",
            "What is 0.0693128 millilitres in litres?\n",
            "How many minutes are there in 83934.55 weeks?\n",
            "How many days are there in ten sevenths of a week?\n",
            "How man\n",
            "58876839\n",
            ".\n",
            "Solve 0 = 43*b + 63224 + 63892 - 128965 for b.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_text[58876790:58876839])\n",
        "print(combined_text[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nsjj_yyvRsx",
        "outputId": "b07c19fb-d0cb-495e-96ab-8460761c446d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "Solve 0 = 43*b + 63224 + 63892 - 128965 for b.\n",
            "\n",
            "What is 3/5 of a millimeter in micrometers?\n",
            "What is 2/21 of a week in seconds?\n",
            "What is 88937.07ms in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Generator\n",
        "\n",
        "The generator is trained using the RNN model proposed in Section 1."
      ],
      "metadata": {
        "id": "JC4MkbCui20v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vectorised dataset\n",
        "text_as_int7, vocabulary7, char2idx7, idx2char7 = process_text(combined_text)\n",
        "dataset7 = define_dataset(text_as_int7, max_length=100, batch_size=64, buffer_size=600000)\n",
        "\n",
        "#Compile model\n",
        "model7 = build_model(vocab_size=len(vocabulary7), batch_size=64)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model7.compile(optimizer, loss=loss)\n",
        "\n",
        "\n",
        "#Train model\n",
        "history7 = model7.fit(dataset7, epochs=1)\n",
        "model7.save_weights(\"gen_text_weights7.h5\", save_format='h5')\n",
        "gen_model7 = build_model(vocab_size=len(vocabulary7), batch_size=1)\n",
        "gen_model7.load_weights(\"gen_text_weights7.h5\")"
      ],
      "metadata": {
        "id": "d2FNjke_jI-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text10 = generate_text(gen_model7, start_string=\"S\", generate_char_num=n_characters_output, char2idx=char2idx7, idx2char=idx2char7)\n",
        "print(generated_text10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAWywvXUoqPN",
        "outputId": "b086a9a0-01ed-479f-91b6-95ef28b326dd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solve 841*r + 39938 + 17849 = -599*r - 29372 for r.\n",
            "Solve 1435*d = -729*d - 390 for d.\n",
            "Solve -17681*l = -12997*l for l.\n",
            "Solve -2229*r = 192*r - 18592 + 19538 for r.\n",
            "Solve -5156377 = 54*k + 8641022 for k.\n",
            "Solve 2733*f + 2350*f - 4693*f + 7584*f = -63686 for f.\n",
            "Solve -59*h + 49288 + 14514 = 0 for h.\n",
            "Solve -50*f + 865521 + 1509313 + 31640 for f.\n",
            "Solve -439*a + 1487 - 33776 = in seconds?\n",
            "How many milliseconds are there in 1/4 of a minute?\n",
            "Convert 9870.467 kilometers in meters?\n",
            "Convert 6782.518 years to months.\n",
            "How many minutes are there in fourty-two fifths of a week?\n",
            "How many centimeters are there in fifteen halves of a gram?\n",
            "What is 57/2 of a kilogram in grams?\n",
            "How many weeks are there in 982.5616 minutes?\n",
            "Convert 87.56705 milligrams to millimeters.\n",
            "How many months are there in 17/4 of a century?\n",
            "What is twenty-three sixths of a hour in minutes?\n",
            "How many nanoseconds are there in 3/5 of a week?\n",
            "How many years are there in 23/4 of a decade?\n",
            "How many centuries are there in 0.93033 years?\n",
            "Wha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model seems to be able to generate both linear algebra and unit conversion questions but it seems to do it in batches with the middle question separating the batches being a fusion of both topics. In this case the problem in question is: \n",
        "\n",
        "\n",
        "```\n",
        "Solve -439*a + 1487 - 33776 = in seconds?\n",
        "```\n",
        "This could perhaps be because each batch in training contains only one topics questions. Next, we attempt to mix the type of questions in each batch.\n"
      ],
      "metadata": {
        "id": "-ffOdzoc-kZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from mathematics dataset. Text files are formatted in\n",
        "# pairs of Question-Answer and so the line with the answer is ommitted\n",
        "\n",
        "# FIRST TOPIC\n",
        "\n",
        "training_folder1 = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file1 = \"measurement__conversion.txt\"  # @param {type: \"string\"}\n",
        "training_file_path1 = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder1+'/'+training_file1\n",
        "text1 = open(training_file_path1, encoding='utf-8').readlines()[::2] \n",
        "\n",
        "\n",
        "# SECOND TOPIC\n",
        "training_folder2 = \"train-hard\"  # @param {type: \"string\"}\n",
        "training_file2 = \"algebra__linear_1d.txt\"  # @param {type: \"string\"}\n",
        "training_file_path2 = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder2+'/'+training_file2\n",
        "text2 = open(training_file_path2, encoding='utf-8').readlines()[::2]\n",
        "\n",
        "combined_list = text1+text2\n",
        "\n",
        "random.shuffle(combined_list)\n",
        "\n",
        "combined_text = (''.join(combined_list))\n",
        "print(combined_text[0:1000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkaNdBGr_c52",
        "outputId": "c337ef4d-89b7-4757-e33f-81d7bada6a17"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is 9.92717 micrograms in tonnes?\n",
            "Solve 0 = 103*a + 11*a - 42*a + 221*a - 25491 for a.\n",
            "How many microseconds are there in one fifth of a millisecond?\n",
            "Solve -372*b = -280*b + 178 + 554 - 180 for b.\n",
            "Solve 1282*h + 233464 + 35476 = -639*h for h.\n",
            "What is 915.0121mg in micrograms?\n",
            "Solve -582*r + 1285548 = 1277400 for r.\n",
            "How many millimeters are there in 3/40 of a kilometer?\n",
            "How many microseconds are there in three eighths of a millisecond?\n",
            "Solve -142329*d = -142209*d + 1080 for d.\n",
            "Solve 3252*s = -2137*s + 1980*s - 1827*s + 162316 for s.\n",
            "Convert 515.7546 centuries to millennia.\n",
            "What is 4/3 of a millennium in months?\n",
            "Solve -1457*t + 4409 = -53871 for t.\n",
            "Solve 12082 - 57556 = 85*d + 1293*d for d.\n",
            "Solve -135*c + 988*c = -17913 for c.\n",
            "Convert 60.10495 days to seconds.\n",
            "Solve 6984*x = 7394*x + 38540 for x.\n",
            "What is 763861.1 millennia in months?\n",
            "How many tonnes are there in 0.5884073mg?\n",
            "Solve 368*f = -5739 + 21931 for f.\n",
            "What is 653608.5 months in millennia?\n",
            "Solve -107*j + 2724 = -2635 - 1275 fo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the questions from each topic are mixed in the data we can train our model again to observe its affect.\n",
        "\n",
        "What we see is that the model correctly produces a mix of both questions in seemingly randomly."
      ],
      "metadata": {
        "id": "xEgjv4i4Ar4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vectorised dataset\n",
        "text_as_int7, vocabulary7, char2idx7, idx2char7 = process_text(combined_text)\n",
        "dataset7 = define_dataset(text_as_int7, max_length=100, batch_size=512, buffer_size=600000)\n",
        "\n",
        "#Compile model\n",
        "model7 = build_model(vocab_size=len(vocabulary7), batch_size=512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model7.compile(optimizer, loss=loss)\n",
        "\n",
        "\n",
        "#Train model\n",
        "history7 = model7.fit(dataset7, epochs=4)\n",
        "model7.save_weights(\"gen_text_weights7.h5\", save_format='h5')\n",
        "gen_model7 = build_model(vocab_size=len(vocabulary7), batch_size=1)\n",
        "gen_model7.load_weights(\"gen_text_weights7.h5\")\n",
        "\n",
        "#Generate questions\n",
        "generated_text10 = generate_text(gen_model7, start_string=\"S\", generate_char_num=n_characters_output, char2idx=char2idx7, idx2char=idx2char7)\n",
        "print(generated_text10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXNSB8YUA8bu",
        "outputId": "764ee57b-7b67-419f-d7b7-1c0a4cd5ed60"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1138/1138 [==============================] - 194s 108ms/step - loss: 1.0579\n",
            "Epoch 2/4\n",
            "1138/1138 [==============================] - 192s 109ms/step - loss: 0.8410\n",
            "Epoch 3/4\n",
            "1138/1138 [==============================] - 193s 109ms/step - loss: 0.8269\n",
            "Epoch 4/4\n",
            "1138/1138 [==============================] - 192s 108ms/step - loss: 0.8212\n",
            "Solve 8201*h = 119733 - 101872 + 392720 for h.\n",
            "Solve -108053 = -3062*l - 94985 for l.\n",
            "Solve 36987 = -4161*x - 1694 + 3462 - 359 for x.\n",
            "How many months are there in 48/5 of a millennium?\n",
            "What is 7/6 of a kilometer in + 3677 = 6885 for x.\n",
            "Convert 431175.9ns to minutes.\n",
            "Solve 3046 = 250*m + 27 - 657 for m.\n",
            "Solve 0 = 131*d + 126*d - 132*d - 6060 for d.\n",
            "What is 6/10 of a microgram in nanograms?\n",
            "Solve 32*s - 881 + 31 = 4 for s.\n",
            "What is 0.4266898nm in centimeters?\n",
            "Convert 41939.54 w many millilitres are there in 17/2 of a litre?\n",
            "How many centimeters are there in 27/4 of a meter?\n",
            "How many months are there in 3/5 of a century?\n",
            "Solve 0 = 876*u + 3038*u - 476*u - 83819 for u.\n",
            "Solve 279*i - 15590 = -163*i - 42*i for i.\n",
            "Solve -144*a + 29*a = -14*a - 30*a for a.\n",
            "Solve 27507*r = -69643*r + 4937 for r.\n",
            "Solve 137*i + 1754060 - 1676299 = 0 for i.\n",
            "What is 0.6569833 minutes in microseconds?\n",
            "Solve 11442*x - 551976 = -113839 for x.\n",
            "Solve -57*r = 1420 - 2614 + 8105 for r.\n",
            "What is eleven eighths of a day in se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training models for our final generator\n",
        "\n"
      ],
      "metadata": {
        "id": "5pAOrjUzHDs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculus\n",
        "training_folder = \"train-hard\"\n",
        "training_file = 'calculus__differentiate.txt'\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text = (''.join(text))\n",
        "text_as_int, vocabulary, char2idx, idx2char = process_text(text)\n",
        "dataset = define_dataset(text_as_int, max_length=100, batch_size=512, buffer_size=10000)\n",
        "model = build_LSTM_model(vocab_size=len(vocabulary), batch_size=512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer, loss=loss)\n",
        "history = model.fit(dataset, epochs=2)\n",
        "model.save_weights(\"gen_text_weights_calc.h5\", save_format='h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "EUkIj-wMJuEN",
        "outputId": "6981a3e5-143e-40ae-e771-534c366a1d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1012/1012 [==============================] - 161s 154ms/step - loss: 1.2138\n",
            "Epoch 2/2\n",
            "1012/1012 [==============================] - 148s 145ms/step - loss: 0.8886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Algebra\n",
        "training_folder = \"train-hard\"\n",
        "training_file = 'algebra__linear_1d.txt'\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text = (''.join(text))\n",
        "text_as_int, vocabulary, char2idx, idx2char = process_text(text)\n",
        "dataset = define_dataset(text_as_int, max_length=100, batch_size=512, buffer_size=10000)\n",
        "model = build_LSTM_model(vocab_size=len(vocabulary), batch_size=512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer, loss=loss)\n",
        "history = model.fit(dataset, epochs=2)\n",
        "model.save_weights(\"gen_text_weights_lin.h5\", save_format='h5')"
      ],
      "metadata": {
        "id": "9PFncI86JyW8",
        "outputId": "cde53ca2-ea88-41f3-a9c9-551349779ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "558/558 [==============================] - 83s 143ms/step - loss: 1.6109\n",
            "Epoch 2/2\n",
            "558/558 [==============================] - 81s 143ms/step - loss: 1.2062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit conversion\n",
        "training_folder = \"train-hard\"\n",
        "training_file = 'measurement__conversion.txt'\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text = (''.join(text))\n",
        "text_as_int, vocabulary, char2idx, idx2char = process_text(text)\n",
        "dataset = define_dataset(text_as_int, max_length=100, batch_size=512, buffer_size=10000)\n",
        "model = build_LSTM_model(vocab_size=len(vocabulary), batch_size=512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer, loss=loss)\n",
        "history = model.fit(dataset, epochs=2)\n",
        "model.save_weights(\"gen_text_weights_unit.h5\", save_format='h5')"
      ],
      "metadata": {
        "id": "LnAlp6J_J2zz",
        "outputId": "629d1793-0e98-4632-d2c6-a9e40c8ee6bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "580/580 [==============================] - 86s 142ms/step - loss: 1.0369\n",
            "Epoch 2/2\n",
            "580/580 [==============================] - 84s 142ms/step - loss: 0.4993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GCD\n",
        "training_folder = \"train-hard\"\n",
        "training_file = 'numbers__gcd.txt'\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "text = (''.join(text))\n",
        "text_as_int, vocabulary, char2idx, idx2char = process_text(text)\n",
        "dataset = define_dataset(text_as_int, max_length=100, batch_size=512, buffer_size=10000)\n",
        "model = build_LSTM_model(vocab_size=len(vocabulary), batch_size=512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer, loss=loss)\n",
        "history = model.fit(dataset, epochs=2)\n",
        "model.save_weights(\"gen_text_weights_gcd.h5\", save_format='h5')"
      ],
      "metadata": {
        "id": "W89EHw4EJ5AK",
        "outputId": "1e7ed74c-52ba-4407-e673-5b05baafc7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "735/735 [==============================] - 108s 142ms/step - loss: 0.8978\n",
            "Epoch 2/2\n",
            "735/735 [==============================] - 106s 142ms/step - loss: 0.5845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. A more challenging dataset**\n",
        "\n",
        "As a further investigation, the model was tested with a more varied dataset of word questions from a number of different topics. This dataset was created using the Microsoft SigmaDolphin dataset, converting a subset of the dataset into a text file. In this dataset 1878 word problems are contained.\n",
        "\n",
        "Dataset available [here](https://msropendata.com/datasets/f0e63bb3-717a-4a53-aa79-da339b0d7992)"
      ],
      "metadata": {
        "id": "_sTGHKs14Im4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "9Q4Ci8py5nIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SigmaDolphin sub-dataset\n",
        "\n",
        "training_file = \"word_problems.txt\"  # @param {type: \"string\"}\n",
        "\n",
        "training_file_path = '/content/gdrive/MyDrive/CCProject/'+training_file\n",
        "\n",
        "dol_text = open(training_file_path, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "\n",
        "# text = (''.join(text))\n"
      ],
      "metadata": {
        "id": "JAGEBaRH4m0q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dol_text[1000:2000])"
      ],
      "metadata": {
        "id": "UwgQdjHb5Ymo",
        "outputId": "d51ecf31-68c8-4a2f-fc7b-44cf656bb383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r, the result is 8. Find the numbers.\n",
            "Find two numbers whose sum is 64 and whose difference is 42.\n",
            "The sum of two numbers is 70. One number is eight more than the other. What are the two numbers?\n",
            "the sum of 2 numbers is 75. the larger number is 3 more than the smaller number. What're the numbers?\n",
            "the sum of two integers is 42. their difference is 8 find the integers.\n",
            "if a number is 2 more than a second and their sum is 30, find the numbers.\n",
            "the sum of two numbers is 50. The difference between these numbers is 10 then find the numbers\n",
            "the sum of two numbers is 64. the smaller number is 12 less than the larger number. What are the two numbers?\n",
            "The sum of two numbers is 55. The smaller is 5 less than the larger. What are the numbers\n",
            "the sum of two numbers is 35. if the larger number is 7 greater than the smaller number, find the numbers\n",
            "The sum of two integers is zero. The difference of the same two integers is 16. What are the two integers?\n",
            "One number is 10 less than another number. If t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training using our LSTM model\n",
        "\n"
      ],
      "metadata": {
        "id": "qQE_zwkj5qCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_LSTM_model(vocab_size=len(vocabulary), embedding_dim=256, rnn_uits=256, batch_size=512):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2), \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "UzkL-qcPBDmw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vectorised dataset\n",
        "text_as_int_d, vocabulary_d, char2idx_d, idx2char_d = process_text(dol_text)\n",
        "dataset_d = define_dataset(text_as_int_d, max_length=150, batch_size=32, buffer_size=600000)\n",
        "\n",
        "#Compile model\n",
        "model_d = build_LSTM_model(vocab_size=len(vocabulary_d), batch_size=32)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "model_d.compile(optimizer, loss=loss)\n",
        "\n",
        "\n",
        "#Train model\n",
        "history_d = model_d.fit(dataset_d, epochs=50)\n",
        "model_d.save_weights(\"gen_text_weights_d.h5\", save_format='h5')\n",
        "gen_model_d = build_LSTM_model(vocab_size=len(vocabulary_d), batch_size=1)\n",
        "gen_model_d.load_weights(\"gen_text_weights_d.h5\")"
      ],
      "metadata": {
        "id": "pqtfHoGe5_ff",
        "outputId": "764afda5-b0e6-48ec-94d1-b20496a8900b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "89/89 [==============================] - 6s 23ms/step - loss: 2.3699\n",
            "Epoch 2/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.9206\n",
            "Epoch 3/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.7246\n",
            "Epoch 4/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.6586\n",
            "Epoch 5/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.6189\n",
            "Epoch 6/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.5922\n",
            "Epoch 7/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.5699\n",
            "Epoch 8/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.5521\n",
            "Epoch 9/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.5394\n",
            "Epoch 10/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.5268\n",
            "Epoch 11/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.5162\n",
            "Epoch 12/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.5083\n",
            "Epoch 13/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4994\n",
            "Epoch 14/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4933\n",
            "Epoch 15/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.4861\n",
            "Epoch 16/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4824\n",
            "Epoch 17/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4750\n",
            "Epoch 18/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.4702\n",
            "Epoch 19/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.4671\n",
            "Epoch 20/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4610\n",
            "Epoch 21/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4586\n",
            "Epoch 22/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4550\n",
            "Epoch 23/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4523\n",
            "Epoch 24/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4484\n",
            "Epoch 25/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4465\n",
            "Epoch 26/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4442\n",
            "Epoch 27/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4413\n",
            "Epoch 28/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4390\n",
            "Epoch 29/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4402\n",
            "Epoch 30/50\n",
            "89/89 [==============================] - 3s 25ms/step - loss: 0.4347\n",
            "Epoch 31/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4337\n",
            "Epoch 32/50\n",
            "89/89 [==============================] - 3s 24ms/step - loss: 0.4318\n",
            "Epoch 33/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4300\n",
            "Epoch 34/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4291\n",
            "Epoch 35/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4296\n",
            "Epoch 36/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4258\n",
            "Epoch 37/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4260\n",
            "Epoch 38/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4268\n",
            "Epoch 39/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.4237\n",
            "Epoch 40/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4249\n",
            "Epoch 41/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4230\n",
            "Epoch 42/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4219\n",
            "Epoch 43/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4207\n",
            "Epoch 44/50\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 0.4210\n",
            "Epoch 45/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4215\n",
            "Epoch 46/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4191\n",
            "Epoch 47/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4195\n",
            "Epoch 48/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4190\n",
            "Epoch 49/50\n",
            "89/89 [==============================] - 3s 22ms/step - loss: 0.4202\n",
            "Epoch 50/50\n",
            "89/89 [==============================] - 3s 23ms/step - loss: 0.4182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate questions\n",
        "generated_text_d = generate_text(gen_model_d, start_string=\"S\", generate_char_num=1000, char2idx=char2idx_d, idx2char=idx2char_d)\n",
        "print(generated_text_d)"
      ],
      "metadata": {
        "id": "y8gqJs_l9AhK",
        "outputId": "39400030-575e-4741-88c7-1c0bcdb57972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SB-15\n",
            "Ab+7=e+TW=6 when ex that is %ive consecutive integers whose sum is 120?\n",
            "the largest of three consecutive even integers is consecutive integers such that the sum of these a number and the sum of the digits is 3ame consecutive odd integers such that the sum of the smallest and fifteen is 5 less than 35 less than three times the first integer. What are these two numbers?\n",
            "The qumbers. the product of one half the result of a sum of -90.\n",
            "One number is 8 more than 5 times the number , and 8, find the number.\n",
            "The sum of two numbers is 5 more than twice the second number. What're the smaller integer.\n",
            "find two consecutive odd integers such that integer is subtracted from the sum of the same numbers of 20., and 4,  # greater than the number. Find the number.\n",
            "four more than a number is -2, and their product?\n",
            "if 64 is added to four times the smaller of two consecutive even integers is 15 less than twice the smaller.\n",
            "The sum of two consecutive odd integers is 08, find the smallest of thesm is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate questions\n",
        "generated_text_d = generate_text(gen_model_d, start_string=\"S\", generate_char_num=1000, char2idx=char2idx_d, idx2char=idx2char_d)\n",
        "print(generated_text_d)"
      ],
      "metadata": {
        "id": "tNGMXaJJCwRa",
        "outputId": "7e0f893a-091c-49f4-c176-9fea4a7d1901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SV$VBBZ)JjjZjQ*jj*_j)_QQQBERDBESWSUMBER IFBGER?\n",
            "FiND WWHt fIRVE INTEGERS SO THAT TWICE THE SUM OF THE FIRST AND THIRD IS 2,B is the same as 13 less than the opposite\n",
            "the sum of two times a number positive integers is 25. What are the integers?\n",
            "the sum of four consecutive even integers is 11 more than the largest, increased by 26. Find the third integers\n",
            "The product of two consecutive odd integers is -286. Find the two integers\n",
            "The sum of two numbers is 32. The difference of the two numbers is 12. find the numbers\n",
            "Find three consecutive odd integers such that the sum of the largest and second is five less than twice the largest. Find the integers\n",
            "find two consecutive even integers such that four times the smaller is 62\n",
            "find 5 consecutive even integers such that the sum of the first and third is difference and seven times the smaller of two consecutive even integers is doubled, the result is  90.\n",
            "What number is 6. Find the number\n",
            "find four consecutive odd integers whose sum is 80\n",
            "the sum \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are suprisingly good, given the small training dataset. Very often the questions are correct syntactically and some times the questions are \"original\" (do not appear in the dataset) and are solvable"
      ],
      "metadata": {
        "id": "YJebU-qKFPhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. An interactive question generator**\n",
        "\n",
        "This is a tool that lets the user select a topic to generate problems on, along with how many problems they would like generated."
      ],
      "metadata": {
        "id": "gyuSbKDn2ajR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "#@title Interactive Generator - double click on this line to see code { display-mode: \"form\" }\n",
        "\n",
        "def problem_generator(topic, number): \n",
        "\n",
        "  training_folder = \"train-hard\"\n",
        "  training_file = topic  \n",
        "  training_file_path = '/content/gdrive/MyDrive/CCProject/mathematics_dataset-v1.0 2/'+training_folder+'/'+training_file\n",
        "  text = open(training_file_path, encoding='utf-8').readlines()[::2] \n",
        "  text = (''.join(text))\n",
        "\n",
        "  text_as_int, vocabulary, char2idx, idx2char = process_text(text)\n",
        "\n",
        "  gen_model = build_LSTM_model(vocab_size=len(vocabulary), batch_size=1)\n",
        "\n",
        "  if topic == 'calculus__differentiate.txt':\n",
        "    gen_model.load_weights(\"gen_text_weights_calc.h5\")\n",
        "    start_string = 'F'\n",
        "\n",
        "  elif topic == 'algebra__linear_1d.txt':\n",
        "    gen_model.load_weights(\"gen_text_weights_lin.h5\")\n",
        "    start_string = 'S'\n",
        "\n",
        "  \n",
        "  elif topic == 'numbers__gcd.txt':\n",
        "    gen_model.load_weights(\"gen_text_weights_gcd.h5\")\n",
        "    start_string = 'W'\n",
        "\n",
        "  \n",
        "  else: \n",
        "    gen_model.load_weights(\"gen_text_weights_unit.h5\")\n",
        "    start_string = 'W'\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  generated_text = generate_text(gen_model, start_string=start_string, generate_char_num=number*150, char2idx=char2idx, idx2char=idx2char)\n",
        "  \n",
        "  question_list = generated_text.split(\"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  return print(*question_list[0:number], sep = \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "topic = \"calculus__differentiate.txt\" #@param [\"calculus__differentiate.txt\", \"algebra__linear_1d.txt\", \"measurement__conversion.txt\", \"numbers__gcd.txt\"] {type:\"string\"}\n",
        "\n",
        "number_of_questions = 10 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "problem_generator(topic, number_of_questions)\n",
        "\n"
      ],
      "metadata": {
        "id": "icEm8eg_3LH6",
        "outputId": "acb88c70-b2fb-4000-d02c-347c14af9d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FWhat is the second derivative of 111*l*r**4 + l*r + 4*l - 2846*r**3 + 4761*r**2 - r - 4 wrt r.\n",
            "Find the second derivative of -3 + 31*o**2 - 2*o + 3 wrt o?\n",
            "What is the second derivative of 584407*b**2*d**2*u**2 - 38*b**2*u**2 + 10*b*l**2*u + 5*b*u - 2*b - 13643*u**4 - u**2 + 1 wrt u.\n",
            "What is the second derivative of -11056416*h**2 - 35*h - 2483006 wrt h.\n",
            "Find the third derivative of 17*d**2*f**3*m + 25369438*d**2*f**2 + v**2*z**2 + 3*f**2*z + 3*d**2 + d*z + 5*d - r*z**5 - 1209*w*z wrt z?\n",
            "What is the second derivative of 2*z**5 - 9*z**4 + 951567*z**3 - 9419305*z - .\n",
            "Find the third derivative of -100499522*b**3 + 52838717*b**2.\n",
            "Find the first derivative of -27926746*s + 14614784 wrt s?\n",
            "Differentiate 9483*d**3*b - 186320*d**3 + 4851113*i**2 wrt d?\n",
            "What is the first derivative of 29.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GenerativeMathProblems.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
